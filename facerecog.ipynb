{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "face_cap=cv2.CascadeClassifier(\"C:/Users/USER/AppData/Local/Programs/Python/Python311/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "#This loads a pre-trained classifier for detecting faces. The XML file specified contains information about how to detect frontal faces.\n",
    "\n",
    "video_cap=cv2.VideoCapture(0)\n",
    "# This opens a connection to the default camera (webcam) to capture video.\n",
    "while True:\n",
    "    # This starts an infinite loop for continuously capturing and processing video frames.\n",
    "    ret , video_data= video_cap.read()\n",
    "     #This captures a frame from the video.\n",
    "     # ret is a boolean indicating whether the frame was successfully captured, and video_data contains the captured frame.\n",
    "    col=cv2.cvtColor(video_data,cv2.COLOR_BGR2GRAY) \n",
    "    # This converts the color of the captured frame to grayscale. Grayscale images are easier to process for face detection.\n",
    "    faces=face_cap.detectMultiScale(                 \n",
    "         #now we have colourised the data\n",
    "        col,\n",
    "         #now we have done detection of muscles in which we have captured data  using some default factors\n",
    "        scaleFactor=1.1,                               \n",
    "        minNeighbors=5,\n",
    "        minSize=(30,30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        #Above block of code detects faces in the grayscale frame. It returns a list of rectangles where faces are detected.\n",
    "    )\n",
    "     \n",
    "    for (x,y,w,h) in faces:    \n",
    "          #This loop iterates over the detected faces and draws rectangles around them.                \n",
    "          cv2.rectangle(video_data,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "          #This draws a green rectangle around each detected face on the original color frame.\n",
    "\n",
    "    cv2.imshow(\"video_live\",video_data)   \n",
    "    #This displays the processed frame with detected faces.\n",
    "\n",
    "    if cv2.waitKey(10)==ord(\"a\"):         \n",
    "        #This line waits for a key press (for 10 milliseconds) and checks if the pressed key is \"a\". \n",
    "        #If \"a\" is pressed, it breaks the loop and ends the program.\n",
    "        break\n",
    "\n",
    "\n",
    "video_cap.release()\n",
    "#This releases the webcam resource once the program finishes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
